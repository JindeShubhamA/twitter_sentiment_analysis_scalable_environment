version: '3'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
    ports:
      - 9200:9200
    networks:
    - msgqueue
    healthcheck:
        test: ["CMD", "curl", "-f", "http://elasticsearch:9200"]
        interval: 30s
        timeout: 10s
        retries: 5

  producer:
    build:
      context: ./python_code
      dockerfile: Dockerfile_producer
    container_name: producer
    networks:
      - msgqueue
    depends_on:
      - elasticsearch
      - kafka
    links:
      - elasticsearch
      - kafka
    restart: on-failure


  consumer:
    build:
      context: ./python_code
      dockerfile: Dockerfile_consumer
    depends_on:
      - kafka
    links:
      - kafka
    container_name: consumer
    restart: on-failure
    networks:
    - msgqueue

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
    networks:
    - msgqueue

  kafka:
    build: python_code/kafka-docker/
    ports:
      - "9092:9092"
      - "9093:9093"
    expose:
      - "9093"
      - "9092"
    container_name: kafka
    environment:
#      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "topic_test:1:1"
    networks:
    - msgqueue
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
#
#  client:
#      image: appropriate/curl:latest
#      networks:
#        - elastic
#      command: "curl http://elasticsearch:9200"
networks:
  msgqueue:
    driver: bridge
